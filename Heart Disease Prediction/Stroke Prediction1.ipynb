{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'hypertension',\n",
       " 'heart_disease',\n",
       " 'ever_married',\n",
       " 'work_type',\n",
       " 'Residence_type',\n",
       " 'avg_glucose_level',\n",
       " 'bmi',\n",
       " 'smoking_status',\n",
       " 'stroke']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"id\",inplace=True)\n",
    "df.drop(columns=\"ever_married\",inplace=True)\n",
    "df.drop(columns=\"work_type\",inplace=True)\n",
    "df.drop(columns=\"Residence_type\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "avg_glucose_level      0\n",
       "bmi                  201\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             5110 non-null   object \n",
      " 1   age                5110 non-null   float64\n",
      " 2   hypertension       5110 non-null   int64  \n",
      " 3   heart_disease      5110 non-null   int64  \n",
      " 4   avg_glucose_level  5110 non-null   float64\n",
      " 5   bmi                4909 non-null   float64\n",
      " 6   smoking_status     5110 non-null   object \n",
      " 7   stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(2)\n",
      "memory usage: 319.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-73eb4983441b>:3: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared\n",
      "  g = df.hist(ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15,15))\n",
    "ax = fig.gca()\n",
    "g = df.hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='stroke', ylabel='count'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQvElEQVR4nO3df6zdd13H8edrHYwxqG6um6N32kkq0g0Z7lqG+0fAuApIKzpSFNfgkuoyDYtGsxkDCmkkAY2MuCUNQltRlkbEVcyQpvLLuKzcwnDrRl3jcGta144fUjAOW97+cT+Vs/b0fu5Gz7m3vc9HcnK+3/f5fr73fZZmr3x/fU6qCkmSZnLWXDcgSZr/DAtJUpdhIUnqMiwkSV2GhSSp6+y5bmBULrzwwlq2bNlctyFJp5Vdu3Y9UVVLjq+fsWGxbNkypqam5roNSTqtJPmPYfWRnoZK8uUk9ye5L8lUq12QZHuSh9v7+QPb35pkb5I9Sa4dqF/V9rM3yW1JMsq+JUlPNY5rFq+sqiurarKt3wLsqKrlwI62TpIVwFrgcmAVcHuSRW3MHcB6YHl7rRpD35KkZi4ucK8GNrflzcCagfqdVfVkVT0C7AVWJrkEWFxV99T04+ZbBsZIksZg1GFRwCeS7EqyvtUurqoDAO39olZfCjw2MHZfqy1ty8fXT5BkfZKpJFOHDh06hV9Dkha2UV/gvqaq9ie5CNie5EszbDvsOkTNUD+xWLUR2AgwOTnppFeSdIqM9Miiqva394PAR4GVwOPt1BLt/WDbfB9w6cDwCWB/q08MqUuSxmRkYZHkvCTPP7YM/CzwALANWNc2Wwfc1Za3AWuTnJPkMqYvZO9sp6oOJ7m63QV1/cAYSdIYjPI01MXAR9tdrmcDf11VH0/yOWBrkhuAR4HrAKpqd5KtwIPAEeCmqjra9nUjsAk4F7i7vSRJY5Iz9fcsJicny4fyJOnpSbJr4FGH/3fGPsH9vbrqd7fMdQuah3a9+/q5bkGaE04kKEnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXyMMiyaIkX0jysbZ+QZLtSR5u7+cPbHtrkr1J9iS5dqB+VZL722e3Jcmo+5Ykfdc4jizeCjw0sH4LsKOqlgM72jpJVgBrgcuBVcDtSRa1MXcA64Hl7bVqDH1LkpqRhkWSCeC1wPsHyquBzW15M7BmoH5nVT1ZVY8Ae4GVSS4BFlfVPVVVwJaBMZKkMRj1kcWfAb8HfGegdnFVHQBo7xe1+lLgsYHt9rXa0rZ8fP0ESdYnmUoydejQoVPyBSRJIwyLJK8DDlbVrtkOGVKrGeonFqs2VtVkVU0uWbJkln9WktRz9gj3fQ3w+iSvAZ4DLE7yIeDxJJdU1YF2iulg234fcOnA+Algf6tPDKlLksZkZEcWVXVrVU1U1TKmL1z/U1W9GdgGrGubrQPuasvbgLVJzklyGdMXsne2U1WHk1zd7oK6fmCMJGkMRnlkcTLvArYmuQF4FLgOoKp2J9kKPAgcAW6qqqNtzI3AJuBc4O72kiSNyVjCoqo+BXyqLX8FePVJttsAbBhSnwKuGF2HkqSZ+AS3JKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHWNLCySPCfJziRfTLI7yR+1+gVJtid5uL2fPzDm1iR7k+xJcu1A/aok97fPbkuSUfUtSTrRKI8sngReVVUvBa4EViW5GrgF2FFVy4EdbZ0kK4C1wOXAKuD2JIvavu4A1gPL22vVCPuWJB1nZGFR077ZVp/VXgWsBja3+mZgTVteDdxZVU9W1SPAXmBlkkuAxVV1T1UVsGVgjCRpDEZ6zSLJoiT3AQeB7VV1L3BxVR0AaO8Xtc2XAo8NDN/Xakvb8vH1YX9vfZKpJFOHDh06pd9FkhaykYZFVR2tqiuBCaaPEq6YYfNh1yFqhvqwv7exqiaranLJkiVPu19J0nBjuRuqqr4OfIrpaw2Pt1NLtPeDbbN9wKUDwyaA/a0+MaQuSRqTUd4NtSTJ97flc4GfAb4EbAPWtc3WAXe15W3A2iTnJLmM6QvZO9upqsNJrm53QV0/MEaSNAZnj3DflwCb2x1NZwFbq+pjSe4Btia5AXgUuA6gqnYn2Qo8CBwBbqqqo21fNwKbgHOBu9tLkjQmIwuLqvpX4GVD6l8BXn2SMRuADUPqU8BM1zskSSPkE9ySpC7DQpLUNauwSLJjNjVJ0plpxmsWSZ4DPBe4sM3hdOyZh8XAC0bcmyRpnuhd4P514Gamg2EX3w2LbwB/Prq2JEnzyYxhUVXvBd6b5Leq6n1j6kmSNM/M6tbZqnpfkp8Clg2OqaotI+pLkjSPzCoskvwl8ELgPuDYg3LHZoCVJJ3hZvtQ3iSwok0RLklaYGb7nMUDwA+OshFJ0vw12yOLC4EHk+xk+hfwAKiq14+kK0nSvDLbsPjDUTYhSZrfZns31KdH3Ygkaf6a7d1Qh/nur9M9m+nf0/5WVS0eVWOSpPljtkcWzx9cT7IGWDmKhiRJ888zmnW2qv4OeNWpbUWSNF/N9jTUGwZWz2L6uQufuZCkBWK2d0P9/MDyEeDLwOpT3o0kaV6a7TWLt4y6EUnS/DXbHz+aSPLRJAeTPJ7kI0kmRt2cJGl+mO0F7g8C25j+XYulwN+3miRpAZhtWCypqg9W1ZH22gQsGWFfkqR5ZLZh8USSNydZ1F5vBr4yysYkSfPHbMPi14A3Av8JHAB+CfCityQtELO9dfadwLqq+hpAkguA9zAdIpKkM9xsjyx+/FhQAFTVV4GXjaYlSdJ8M9uwOCvJ+cdW2pHFbI9KJEmnudn+D/9PgH9J8jdMT/PxRmDDyLqSJM0rs32Ce0uSKaYnDwzwhqp6cKSdSZLmjVmfSmrhYEBI0gL0jKYolyQtLIaFJKnLsJAkdY0sLJJcmuSTSR5KsjvJW1v9giTbkzzc3gdvyb01yd4ke5JcO1C/Ksn97bPbkmRUfUuSTjTKI4sjwO9U1YuBq4GbkqwAbgF2VNVyYEdbp322FrgcWAXcnmRR29cdwHpgeXutGmHfkqTjjCwsqupAVX2+LR8GHmJ6evPVwOa22WZgTVteDdxZVU9W1SPAXmBlkkuAxVV1T1UVsGVgjCRpDMZyzSLJMqanB7kXuLiqDsB0oAAXtc2WAo8NDNvXakvb8vF1SdKYjDwskjwP+Ahwc1V9Y6ZNh9Rqhvqwv7U+yVSSqUOHDj39ZiVJQ400LJI8i+mg+Kuq+ttWfrydWqK9H2z1fcClA8MngP2tPjGkfoKq2lhVk1U1uWSJv80kSafKKO+GCvAXwENV9acDH20D1rXldcBdA/W1Sc5JchnTF7J3tlNVh5Nc3fZ5/cAYSdIYjHLm2GuAXwXuT3Jfq/0+8C5ga5IbgEeB6wCqaneSrUxPKXIEuKmqjrZxNwKbgHOBu9tLkjQmIwuLqvpnhl9vAHj1ScZsYMhstlU1BVxx6rqTJD0dPsEtSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV0jC4skH0hyMMkDA7ULkmxP8nB7P3/gs1uT7E2yJ8m1A/WrktzfPrstSUbVsyRpuFEeWWwCVh1XuwXYUVXLgR1tnSQrgLXA5W3M7UkWtTF3AOuB5e11/D4lSSM2srCoqs8AXz2uvBrY3JY3A2sG6ndW1ZNV9QiwF1iZ5BJgcVXdU1UFbBkYI0kak3Ffs7i4qg4AtPeLWn0p8NjAdvtabWlbPr4+VJL1SaaSTB06dOiUNi5JC9l8ucA97DpEzVAfqqo2VtVkVU0uWbLklDUnSQvduMPi8XZqifZ+sNX3AZcObDcB7G/1iSF1SdIYjTsstgHr2vI64K6B+tok5yS5jOkL2TvbqarDSa5ud0FdPzBGkjQmZ49qx0k+DPw0cGGSfcDbgXcBW5PcADwKXAdQVbuTbAUeBI4AN1XV0barG5m+s+pc4O72kiSN0cjCoqredJKPXn2S7TcAG4bUp4ArTmFrkqSnab5c4JYkzWOGhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSp6+y5bkDS0/foO14y1y1oHvqht90/sn17ZCFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkrpOm7BIsirJniR7k9wy1/1I0kJyWoRFkkXAnwM/B6wA3pRkxdx2JUkLx2kRFsBKYG9V/XtVfRu4E1g9xz1J0oJxukz3sRR4bGB9H/Dy4zdKsh5Y31a/mWTPGHpbCC4EnpjrJuaDvGfdXLegE/nv85i351Ts5YeHFU+XsBj2X6BOKFRtBDaOvp2FJclUVU3OdR/SMP77HI/T5TTUPuDSgfUJYP8c9SJJC87pEhafA5YnuSzJs4G1wLY57kmSFozT4jRUVR1J8pvAPwKLgA9U1e45bmsh8dSe5jP/fY5Bqk449S9J0lOcLqehJElzyLCQJHUZFpqR06xovkrygSQHkzww170sBIaFTsppVjTPbQJWzXUTC4VhoZk4zYrmrar6DPDVue5joTAsNJNh06wsnaNeJM0hw0IzmdU0K5LOfIaFZuI0K5IAw0Izc5oVSYBhoRlU1RHg2DQrDwFbnWZF80WSDwP3AC9Ksi/JDXPd05nM6T4kSV0eWUiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkE6RJDcnee7THLPMWVN1OjAspFPnZmBoWLQZfKXTlmEhPQNJzkvyD0m+mOSBJG8HXgB8Mskn2zbfTPKOJPcCr0jy223bB5LcPGSfP5LkC0l+MskLk3w8ya4kn03yY+P9htJTnT3XDUinqVXA/qp6LUCS7wPeAryyqp5o25wHPFBVb0tyVfv85UxP0Hhvkk8DX2vjX8T0FPBvqar7kuwAfqOqHk7ycuB24FVj/H7SU/gEt/QMJPlRpqdB2Qp8rKo+m+TLwOSxsEhyBDinqo4meSvwA1X1tvbZO4FDTM+1dS/TofGLVbU7yfPaZ3sG/uQ5VfXiMX096QQeWUjPQFX9WztaeA3wx0k+MWSz/6mqo2152HTvx/wX078bcg2wm+nTw1+vqitPYcvS98RrFtIzkOQFwH9X1YeA9wA/ARwGnn+SIZ8B1iR5bpLzgF8APts++zawBrg+yS9X1TeAR5Jc1/5Wkrx0dN9G6vPIQnpmXgK8O8l3gP8FbgReAdyd5EBVvXJw46r6fJJNwM5Wen9VfSHJsvb5t5K8Dtie5FvArwB3JPkD4FlMX8/44hi+lzSU1ywkSV2ehpIkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV3/B0kcSPK/YzHLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'stroke',data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4861\n",
       "1     249\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stroke'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease  avg_glucose_level   bmi  \\\n",
       "0    Male  67.0             0              1             228.69  36.6   \n",
       "1  Female  61.0             0              0             202.21   NaN   \n",
       "2    Male  80.0             0              1             105.92  32.5   \n",
       "3  Female  49.0             0              0             171.23  34.4   \n",
       "4  Female  79.0             1              0             174.12  24.0   \n",
       "\n",
       "    smoking_status  stroke  \n",
       "0  formerly smoked       1  \n",
       "1     never smoked       1  \n",
       "2     never smoked       1  \n",
       "3           smokes       1  \n",
       "4     never smoked       1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>4909.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.226614</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>106.147677</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>0.048728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.612647</td>\n",
       "      <td>0.296607</td>\n",
       "      <td>0.226063</td>\n",
       "      <td>45.283560</td>\n",
       "      <td>7.854067</td>\n",
       "      <td>0.215320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.120000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.245000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.885000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.090000</td>\n",
       "      <td>33.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271.740000</td>\n",
       "      <td>97.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  hypertension  heart_disease  avg_glucose_level  \\\n",
       "count  5110.000000   5110.000000    5110.000000        5110.000000   \n",
       "mean     43.226614      0.097456       0.054012         106.147677   \n",
       "std      22.612647      0.296607       0.226063          45.283560   \n",
       "min       0.080000      0.000000       0.000000          55.120000   \n",
       "25%      25.000000      0.000000       0.000000          77.245000   \n",
       "50%      45.000000      0.000000       0.000000          91.885000   \n",
       "75%      61.000000      0.000000       0.000000         114.090000   \n",
       "max      82.000000      1.000000       1.000000         271.740000   \n",
       "\n",
       "               bmi       stroke  \n",
       "count  4909.000000  5110.000000  \n",
       "mean     28.893237     0.048728  \n",
       "std       7.854067     0.215320  \n",
       "min      10.300000     0.000000  \n",
       "25%      23.500000     0.000000  \n",
       "50%      28.100000     0.000000  \n",
       "75%      33.100000     0.000000  \n",
       "max      97.600000     1.000000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male' 'Female' 'Other']\n",
      "[0 1]\n",
      "[1 0]\n",
      "['formerly smoked' 'never smoked' 'smokes' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "catFeatures = ['gender', 'hypertension', 'heart_disease', 'smoking_status']\n",
    "for catFeature in catFeatures:\n",
    "    print(df[catFeature].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for catFeature in catFeatures:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.countplot(x = df[catFeature])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender']=df['gender'].map({'Female':0,'Male':1})\n",
    "df['smoking_status']=df['smoking_status'].map({'never smoked':0,'smokes':1,'formerly smoked':2,'Unknown':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'age',\n",
       " 'hypertension',\n",
       " 'heart_disease',\n",
       " 'avg_glucose_level',\n",
       " 'bmi',\n",
       " 'smoking_status',\n",
       " 'stroke']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease  avg_glucose_level   bmi  \\\n",
       "0     1.0  67.0             0              1             228.69  36.6   \n",
       "1     0.0  61.0             0              0             202.21   NaN   \n",
       "2     1.0  80.0             0              1             105.92  32.5   \n",
       "3     0.0  49.0             0              0             171.23  34.4   \n",
       "4     0.0  79.0             1              0             174.12  24.0   \n",
       "\n",
       "   smoking_status  stroke  \n",
       "0               2       1  \n",
       "1               0       1  \n",
       "2               0       1  \n",
       "3               1       1  \n",
       "4               0       1  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                 1\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "avg_glucose_level      0\n",
       "bmi                  201\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df['bmi'].mean())\n",
    "df['smoking_status'].fillna(df['smoking_status'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"gender\",\"age\",\"hypertension\",\"heart_disease\",\"avg_glucose_level\",\"bmi\",\"smoking_status\"]]\n",
    "y = df[\"stroke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(X_resampled, y_resampled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(x_train, y_train)\n",
    "y_pred = model_rf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Score of RandomForestClassifier is: 100.000%\n",
      "The Confusion Matrix for RandomForestClassifier is: \n",
      "[[34 12]\n",
      " [14 40]]\n",
      "\n",
      "The Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72        46\n",
      "           1       0.77      0.74      0.75        54\n",
      "\n",
      "    accuracy                           0.74       100\n",
      "   macro avg       0.74      0.74      0.74       100\n",
      "weighted avg       0.74      0.74      0.74       100\n",
      "\n",
      "\n",
      "The Accuracy Score of RandomForestClassifier is: 74.000%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"The Training Score of RandomForestClassifier is: {:.3f}%\".format(model_rf.score(x_train, y_train)*100))\n",
    "print(\"The Confusion Matrix for RandomForestClassifier is: \\n{}\\n\".format(confusion_matrix(y_test, y_pred)))\n",
    "print(\"The Classification report: \\n{}\\n\".format(classification_report(y_test, y_pred)))\n",
    "print(\"The Accuracy Score of RandomForestClassifier is: {:.3f}%\".format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_param = {\n",
    "    \"n_estimators\" : [90,100,115,130],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth' : range(2,20,1),\n",
    "    'min_samples_leaf' : range(1,10,1),\n",
    "    'min_samples_split': range(2,10,1),\n",
    "    'max_features' : ['auto','log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_search = RandomizedSearchCV(estimator=model_rf,param_distributions=Rand_param,cv=5,verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=7, max_features=log2, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.700 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=7, max_features=log2, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.825 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=7, max_features=log2, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=7, max_features=log2, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.785 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=7, max_features=log2, min_samples_leaf=6, min_samples_split=8, n_estimators=100;, score=0.797 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=17, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=130;, score=0.700 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=17, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=130;, score=0.800 total time=   0.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=17, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=130;, score=0.800 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=17, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=130;, score=0.797 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=17, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=130;, score=0.810 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=7, n_estimators=115;, score=0.688 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=7, n_estimators=115;, score=0.838 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=7, n_estimators=115;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=7, n_estimators=115;, score=0.785 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=7, n_estimators=115;, score=0.785 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=0.688 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=0.812 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=0.823 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=0.797 total time=   0.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=15, max_features=auto, min_samples_leaf=6, min_samples_split=6, n_estimators=115;, score=0.713 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=15, max_features=auto, min_samples_leaf=6, min_samples_split=6, n_estimators=115;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=15, max_features=auto, min_samples_leaf=6, min_samples_split=6, n_estimators=115;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=15, max_features=auto, min_samples_leaf=6, min_samples_split=6, n_estimators=115;, score=0.785 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=15, max_features=auto, min_samples_leaf=6, min_samples_split=6, n_estimators=115;, score=0.810 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=12, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=130;, score=0.713 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=12, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=130;, score=0.825 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=12, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=130;, score=0.812 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=12, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=130;, score=0.797 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=12, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=130;, score=0.797 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=9, max_features=auto, min_samples_leaf=8, min_samples_split=7, n_estimators=100;, score=0.700 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=9, max_features=auto, min_samples_leaf=8, min_samples_split=7, n_estimators=100;, score=0.812 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=9, max_features=auto, min_samples_leaf=8, min_samples_split=7, n_estimators=100;, score=0.812 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=9, max_features=auto, min_samples_leaf=8, min_samples_split=7, n_estimators=100;, score=0.785 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=9, max_features=auto, min_samples_leaf=8, min_samples_split=7, n_estimators=100;, score=0.835 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=115;, score=0.725 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=115;, score=0.825 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=115;, score=0.825 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=115;, score=0.823 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=115;, score=0.823 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=0.725 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=0.812 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=0.797 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=16, max_features=auto, min_samples_leaf=3, min_samples_split=7, n_estimators=130;, score=0.700 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=16, max_features=auto, min_samples_leaf=3, min_samples_split=7, n_estimators=130;, score=0.838 total time=   0.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=16, max_features=auto, min_samples_leaf=3, min_samples_split=7, n_estimators=130;, score=0.800 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=16, max_features=auto, min_samples_leaf=3, min_samples_split=7, n_estimators=130;, score=0.797 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=16, max_features=auto, min_samples_leaf=3, min_samples_split=7, n_estimators=130;, score=0.810 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(2, 20),\n",
       "                                        'max_features': ['auto', 'log2'],\n",
       "                                        'min_samples_leaf': range(1, 10),\n",
       "                                        'min_samples_split': range(2, 10),\n",
       "                                        'n_estimators': [90, 100, 115, 130]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 115,\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 3,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf= RandomForestClassifier(n_estimators=115,\n",
    " min_samples_split=3,\n",
    " min_samples_leaf=1,\n",
    " max_features= 'auto',\n",
    " max_depth= 3,\n",
    " criterion= 'gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, min_samples_split=3, n_estimators=115)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Score of KNeighborsClassifier is: 82.412%\n",
      "The Confusion Matrix for KNeighborsClassifierr is: \n",
      "[[30 16]\n",
      " [12 42]]\n",
      "\n",
      "The Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68        46\n",
      "           1       0.72      0.78      0.75        54\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.72      0.71      0.72       100\n",
      "weighted avg       0.72      0.72      0.72       100\n",
      "\n",
      "\n",
      "The Accuracy Score of KNeighborsClassifier is: 72.000%\n"
     ]
    }
   ],
   "source": [
    "print(\"The Training Score of KNeighborsClassifier is: {:.3f}%\".format(knn.score(x_train, y_train)*100))\n",
    "print(\"The Confusion Matrix for KNeighborsClassifierr is: \\n{}\\n\".format(confusion_matrix(y_test, y_pred)))\n",
    "print(\"The Classification report: \\n{}\\n\".format(classification_report(y_test, y_pred)))\n",
    "print(\"The Accuracy Score of KNeighborsClassifier is: {:.3f}%\".format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_param =  { 'algorithm' : ['ball_tree', 'kd_tree', 'brute'],\n",
    "               'leaf_size' : [18,20,25,27,30,32,34],\n",
    "               'n_neighbors' : [3,5,7,9,10,11,12,13]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_search = RandomizedSearchCV(estimator=knn,param_distributions=Rand_param,verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END algorithm=brute, leaf_size=20, n_neighbors=13;, score=0.700 total time=   0.4s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=20, n_neighbors=13;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=20, n_neighbors=13;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=20, n_neighbors=13;, score=0.734 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=20, n_neighbors=13;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=34, n_neighbors=12;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=34, n_neighbors=12;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=34, n_neighbors=12;, score=0.762 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=34, n_neighbors=12;, score=0.696 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=34, n_neighbors=12;, score=0.734 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=30, n_neighbors=13;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=30, n_neighbors=13;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=30, n_neighbors=13;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=30, n_neighbors=13;, score=0.734 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=30, n_neighbors=13;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=3;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=3;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=3;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=3;, score=0.684 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=3;, score=0.709 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=27, n_neighbors=13;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=27, n_neighbors=13;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=27, n_neighbors=13;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=27, n_neighbors=13;, score=0.734 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=27, n_neighbors=13;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=27, n_neighbors=10;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=27, n_neighbors=10;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=27, n_neighbors=10;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=27, n_neighbors=10;, score=0.671 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=27, n_neighbors=10;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=32, n_neighbors=10;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=32, n_neighbors=10;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=32, n_neighbors=10;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=32, n_neighbors=10;, score=0.671 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=32, n_neighbors=10;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=9;, score=0.675 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=9;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=9;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=9;, score=0.696 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=9;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=0.675 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=25, n_neighbors=5;, score=0.734 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=11;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=11;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=11;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=11;, score=0.709 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=11;, score=0.785 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=KNeighborsClassifier(),\n",
       "                   param_distributions={'algorithm': ['ball_tree', 'kd_tree',\n",
       "                                                      'brute'],\n",
       "                                        'leaf_size': [18, 20, 25, 27, 30, 32,\n",
       "                                                      34],\n",
       "                                        'n_neighbors': [3, 5, 7, 9, 10, 11, 12,\n",
       "                                                        13]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 13, 'leaf_size': 20, 'algorithm': 'brute'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm = 'brute', leaf_size =20, n_neighbors =13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=13)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7914572864321608"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix for knnClassifier is: \n",
      "[[30 16]\n",
      " [12 42]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The Confusion Matrix for knnClassifier is: \\n{}\\n\".format(confusion_matrix(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score1 = Rand_search.predict_proba(x_test)[:,1]\n",
    "y_score2 = knn.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score for Random forest:  0.7163050134895808\n",
      "roc_auc_score for KNN:  0.7163050134895808\n"
     ]
    }
   ],
   "source": [
    "print('roc_auc_score for Random forest: ', roc_auc_score(y_test, y_score1))\n",
    "print('roc_auc_score for KNN: ', roc_auc_score(y_test, y_score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:07:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier(objective='binary:logistic')\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators':[90,100,115,130],\n",
    "              'learning_rate': stats.uniform(0.01, 0.6),\n",
    "              'subsample': stats.uniform(0.3, 0.9),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.9),\n",
    "              'min_child_weight': [1, 2, 3, 4]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(model, param_distributions = param_dist, n_iter = 25, scoring = 'accuracy', error_score = 0, verbose = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.34926 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.34926 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.34926 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.34926 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.34926 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=1.3492577762275118, learning_rate=0.4899137984117142, max_depth=3, min_child_weight=1, n_estimators=90, subsample=0.4088374535565672;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.3492577762275118, learning_rate=0.4899137984117142, max_depth=3, min_child_weight=1, n_estimators=90, subsample=0.4088374535565672;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.3492577762275118, learning_rate=0.4899137984117142, max_depth=3, min_child_weight=1, n_estimators=90, subsample=0.4088374535565672;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.3492577762275118, learning_rate=0.4899137984117142, max_depth=3, min_child_weight=1, n_estimators=90, subsample=0.4088374535565672;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.3492577762275118, learning_rate=0.4899137984117142, max_depth=3, min_child_weight=1, n_estimators=90, subsample=0.4088374535565672;, score=0.000 total time=   0.0s\n",
      "[17:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END colsample_bytree=0.7804529544642649, learning_rate=0.2934170571800207, max_depth=9, min_child_weight=3, n_estimators=90, subsample=0.342166986259245;, score=0.725 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.7804529544642649, learning_rate=0.2934170571800207, max_depth=9, min_child_weight=3, n_estimators=90, subsample=0.342166986259245;, score=0.812 total time=   0.0s\n",
      "[17:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END colsample_bytree=0.7804529544642649, learning_rate=0.2934170571800207, max_depth=9, min_child_weight=3, n_estimators=90, subsample=0.342166986259245;, score=0.825 total time=   0.0s\n",
      "[17:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.7804529544642649, learning_rate=0.2934170571800207, max_depth=9, min_child_weight=3, n_estimators=90, subsample=0.342166986259245;, score=0.873 total time=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[17:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.7804529544642649, learning_rate=0.2934170571800207, max_depth=9, min_child_weight=3, n_estimators=90, subsample=0.342166986259245;, score=0.797 total time=   0.0s\n",
      "[17:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END colsample_bytree=0.9716102719210801, learning_rate=0.18010444113896965, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.9595756191564062;, score=0.713 total time=   0.0s\n",
      "[17:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.9716102719210801, learning_rate=0.18010444113896965, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.9595756191564062;, score=0.812 total time=   0.0s\n",
      "[17:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END colsample_bytree=0.9716102719210801, learning_rate=0.18010444113896965, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.9595756191564062;, score=0.800 total time=   0.0s\n",
      "[17:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.9716102719210801, learning_rate=0.18010444113896965, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.9595756191564062;, score=0.835 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16204 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16204 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16204 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16204 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16204 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.9716102719210801, learning_rate=0.18010444113896965, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.9595756191564062;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.1620361787725946, learning_rate=0.23819453586637715, max_depth=4, min_child_weight=1, n_estimators=90, subsample=0.9297965372874064;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.1620361787725946, learning_rate=0.23819453586637715, max_depth=4, min_child_weight=1, n_estimators=90, subsample=0.9297965372874064;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.1620361787725946, learning_rate=0.23819453586637715, max_depth=4, min_child_weight=1, n_estimators=90, subsample=0.9297965372874064;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.1620361787725946, learning_rate=0.23819453586637715, max_depth=4, min_child_weight=1, n_estimators=90, subsample=0.9297965372874064;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.1620361787725946, learning_rate=0.23819453586637715, max_depth=4, min_child_weight=1, n_estimators=90, subsample=0.9297965372874064;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.2071276345075468, learning_rate=0.5475878165368147, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7066870444264644;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.20713 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.20713 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.20713 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.20713 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.20713 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17741 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17741 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17741 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17741 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17741 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19756 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19756 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19756 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END colsample_bytree=1.2071276345075468, learning_rate=0.5475878165368147, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7066870444264644;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.2071276345075468, learning_rate=0.5475878165368147, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7066870444264644;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.2071276345075468, learning_rate=0.5475878165368147, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7066870444264644;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.2071276345075468, learning_rate=0.5475878165368147, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7066870444264644;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.1774119537346377, learning_rate=0.07810363535108332, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.9833190324620436;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.1774119537346377, learning_rate=0.07810363535108332, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.9833190324620436;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.1774119537346377, learning_rate=0.07810363535108332, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.9833190324620436;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.1774119537346377, learning_rate=0.07810363535108332, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.9833190324620436;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.1774119537346377, learning_rate=0.07810363535108332, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.9833190324620436;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.197555296501808, learning_rate=0.034433848733885365, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7205657199837843;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.197555296501808, learning_rate=0.034433848733885365, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7205657199837843;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.197555296501808, learning_rate=0.034433848733885365, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7205657199837843;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.197555296501808, learning_rate=0.034433848733885365, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7205657199837843;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19756 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19756 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02282 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02282 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02282 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02282 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02282 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35858 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35858 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35858 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35858 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35858 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36021 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=1.197555296501808, learning_rate=0.034433848733885365, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7205657199837843;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0228217651171327, learning_rate=0.26216609951031444, max_depth=8, min_child_weight=2, n_estimators=90, subsample=0.3542342547296248;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0228217651171327, learning_rate=0.26216609951031444, max_depth=8, min_child_weight=2, n_estimators=90, subsample=0.3542342547296248;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0228217651171327, learning_rate=0.26216609951031444, max_depth=8, min_child_weight=2, n_estimators=90, subsample=0.3542342547296248;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0228217651171327, learning_rate=0.26216609951031444, max_depth=8, min_child_weight=2, n_estimators=90, subsample=0.3542342547296248;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0228217651171327, learning_rate=0.26216609951031444, max_depth=8, min_child_weight=2, n_estimators=90, subsample=0.3542342547296248;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.3585835229059062, learning_rate=0.14705789659801058, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.1920090653516624;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.3585835229059062, learning_rate=0.14705789659801058, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.1920090653516624;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.3585835229059062, learning_rate=0.14705789659801058, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.1920090653516624;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.3585835229059062, learning_rate=0.14705789659801058, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.1920090653516624;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.3585835229059062, learning_rate=0.14705789659801058, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.1920090653516624;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.360207122136352, learning_rate=0.16424846491029846, max_depth=4, min_child_weight=4, n_estimators=90, subsample=0.5730510369161258;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.360207122136352, learning_rate=0.16424846491029846, max_depth=4, min_child_weight=4, n_estimators=90, subsample=0.5730510369161258;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36021 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36021 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36021 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36021 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=1.360207122136352, learning_rate=0.16424846491029846, max_depth=4, min_child_weight=4, n_estimators=90, subsample=0.5730510369161258;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.360207122136352, learning_rate=0.16424846491029846, max_depth=4, min_child_weight=4, n_estimators=90, subsample=0.5730510369161258;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.360207122136352, learning_rate=0.16424846491029846, max_depth=4, min_child_weight=4, n_estimators=90, subsample=0.5730510369161258;, score=0.000 total time=   0.0s\n",
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END colsample_bytree=0.9852573585954923, learning_rate=0.5834255768353324, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.7993664549892479;, score=0.700 total time=   0.0s\n",
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.9852573585954923, learning_rate=0.5834255768353324, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.7993664549892479;, score=0.787 total time=   0.0s\n",
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END colsample_bytree=0.9852573585954923, learning_rate=0.5834255768353324, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.7993664549892479;, score=0.812 total time=   0.0s\n",
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.9852573585954923, learning_rate=0.5834255768353324, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.7993664549892479;, score=0.772 total time=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.9852573585954923, learning_rate=0.5834255768353324, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.7993664549892479;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0054072384345876, learning_rate=0.4172711316912341, max_depth=3, min_child_weight=3, n_estimators=130, subsample=0.38773222892528325;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0054072384345876, learning_rate=0.4172711316912341, max_depth=3, min_child_weight=3, n_estimators=130, subsample=0.38773222892528325;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0054072384345876, learning_rate=0.4172711316912341, max_depth=3, min_child_weight=3, n_estimators=130, subsample=0.38773222892528325;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0054072384345876, learning_rate=0.4172711316912341, max_depth=3, min_child_weight=3, n_estimators=130, subsample=0.38773222892528325;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0054072384345876, learning_rate=0.4172711316912341, max_depth=3, min_child_weight=3, n_estimators=130, subsample=0.38773222892528325;, score=0.000 total time=   0.0s\n",
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00541 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00541 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00541 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00541 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00541 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.7367807801354228, learning_rate=0.5621678056943338, max_depth=9, min_child_weight=3, n_estimators=115, subsample=0.699691140722458;, score=0.713 total time=   0.0s\n",
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.7367807801354228, learning_rate=0.5621678056943338, max_depth=9, min_child_weight=3, n_estimators=115, subsample=0.699691140722458;, score=0.800 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END colsample_bytree=0.7367807801354228, learning_rate=0.5621678056943338, max_depth=9, min_child_weight=3, n_estimators=115, subsample=0.699691140722458;, score=0.787 total time=   0.0s\n",
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.7367807801354228, learning_rate=0.5621678056943338, max_depth=9, min_child_weight=3, n_estimators=115, subsample=0.699691140722458;, score=0.848 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02142 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02142 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02142 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02142 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02142 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.7367807801354228, learning_rate=0.5621678056943338, max_depth=9, min_child_weight=3, n_estimators=115, subsample=0.699691140722458;, score=0.722 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.5071301249949955, learning_rate=0.5506061004845505, max_depth=9, min_child_weight=3, n_estimators=90, subsample=1.0214181834507325;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.5071301249949955, learning_rate=0.5506061004845505, max_depth=9, min_child_weight=3, n_estimators=90, subsample=1.0214181834507325;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.5071301249949955, learning_rate=0.5506061004845505, max_depth=9, min_child_weight=3, n_estimators=90, subsample=1.0214181834507325;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.5071301249949955, learning_rate=0.5506061004845505, max_depth=9, min_child_weight=3, n_estimators=90, subsample=1.0214181834507325;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.5071301249949955, learning_rate=0.5506061004845505, max_depth=9, min_child_weight=3, n_estimators=90, subsample=1.0214181834507325;, score=0.000 total time=   0.0s\n",
      "[17:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.5691416992843472, learning_rate=0.32675134983123727, max_depth=9, min_child_weight=2, n_estimators=115, subsample=0.9052494645755156;, score=0.637 total time=   0.0s\n",
      "[17:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.5691416992843472, learning_rate=0.32675134983123727, max_depth=9, min_child_weight=2, n_estimators=115, subsample=0.9052494645755156;, score=0.775 total time=   0.0s\n",
      "[17:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=0.5691416992843472, learning_rate=0.32675134983123727, max_depth=9, min_child_weight=2, n_estimators=115, subsample=0.9052494645755156;, score=0.750 total time=   0.0s\n",
      "[17:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.5691416992843472, learning_rate=0.32675134983123727, max_depth=9, min_child_weight=2, n_estimators=115, subsample=0.9052494645755156;, score=0.747 total time=   0.0s\n",
      "[17:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=0.5691416992843472, learning_rate=0.32675134983123727, max_depth=9, min_child_weight=2, n_estimators=115, subsample=0.9052494645755156;, score=0.722 total time=   0.0s\n",
      "[17:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END colsample_bytree=0.5931747855039357, learning_rate=0.419720094297598, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.6899509745158101;, score=0.713 total time=   0.0s\n",
      "[17:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.5931747855039357, learning_rate=0.419720094297598, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.6899509745158101;, score=0.838 total time=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[17:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END colsample_bytree=0.5931747855039357, learning_rate=0.419720094297598, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.6899509745158101;, score=0.775 total time=   0.0s\n",
      "[17:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END colsample_bytree=0.5931747855039357, learning_rate=0.419720094297598, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.6899509745158101;, score=0.772 total time=   0.0s\n",
      "[17:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.5931747855039357, learning_rate=0.419720094297598, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.6899509745158101;, score=0.734 total time=   0.0s\n",
      "[17:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END colsample_bytree=0.6480681451590187, learning_rate=0.2829787432577512, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9598859507631334;, score=0.688 total time=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[17:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.6480681451590187, learning_rate=0.2829787432577512, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9598859507631334;, score=0.800 total time=   0.0s\n",
      "[17:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END colsample_bytree=0.6480681451590187, learning_rate=0.2829787432577512, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9598859507631334;, score=0.787 total time=   0.0s\n",
      "[17:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18155 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 4/5] END colsample_bytree=0.6480681451590187, learning_rate=0.2829787432577512, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9598859507631334;, score=0.823 total time=   0.0s\n",
      "[17:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.6480681451590187, learning_rate=0.2829787432577512, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.9598859507631334;, score=0.709 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.1815482375712492, learning_rate=0.5681790625203686, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7559122244951471;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18155 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18155 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18155 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18155 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06325 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06325 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06325 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06325 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06325 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END colsample_bytree=1.1815482375712492, learning_rate=0.5681790625203686, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7559122244951471;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.1815482375712492, learning_rate=0.5681790625203686, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7559122244951471;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.1815482375712492, learning_rate=0.5681790625203686, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7559122244951471;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.1815482375712492, learning_rate=0.5681790625203686, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7559122244951471;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.5181965196697481, learning_rate=0.2913399236885742, max_depth=7, min_child_weight=1, n_estimators=130, subsample=1.063247575764211;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.5181965196697481, learning_rate=0.2913399236885742, max_depth=7, min_child_weight=1, n_estimators=130, subsample=1.063247575764211;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.5181965196697481, learning_rate=0.2913399236885742, max_depth=7, min_child_weight=1, n_estimators=130, subsample=1.063247575764211;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.5181965196697481, learning_rate=0.2913399236885742, max_depth=7, min_child_weight=1, n_estimators=130, subsample=1.063247575764211;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.5181965196697481, learning_rate=0.2913399236885742, max_depth=7, min_child_weight=1, n_estimators=130, subsample=1.063247575764211;, score=0.000 total time=   0.0s\n",
      "[17:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END colsample_bytree=0.5075052250334837, learning_rate=0.32896390475381615, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.8496426683567186;, score=0.688 total time=   0.0s\n",
      "[17:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.5075052250334837, learning_rate=0.32896390475381615, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.8496426683567186;, score=0.838 total time=   0.0s\n",
      "[17:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END colsample_bytree=0.5075052250334837, learning_rate=0.32896390475381615, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.8496426683567186;, score=0.762 total time=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[17:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.5075052250334837, learning_rate=0.32896390475381615, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.8496426683567186;, score=0.785 total time=   0.0s\n",
      "[17:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38948 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38948 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38948 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38948 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38948 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10135 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10135 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=0.5075052250334837, learning_rate=0.32896390475381615, max_depth=3, min_child_weight=4, n_estimators=115, subsample=0.8496426683567186;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.3894830147805588, learning_rate=0.49034609482256486, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.5805771112210707;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.3894830147805588, learning_rate=0.49034609482256486, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.5805771112210707;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.3894830147805588, learning_rate=0.49034609482256486, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.5805771112210707;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.3894830147805588, learning_rate=0.49034609482256486, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.5805771112210707;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.3894830147805588, learning_rate=0.49034609482256486, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.5805771112210707;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.1013495155434563, learning_rate=0.11191953783102526, max_depth=5, min_child_weight=1, n_estimators=90, subsample=1.0729473890031747;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.1013495155434563, learning_rate=0.11191953783102526, max_depth=5, min_child_weight=1, n_estimators=90, subsample=1.0729473890031747;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.1013495155434563, learning_rate=0.11191953783102526, max_depth=5, min_child_weight=1, n_estimators=90, subsample=1.0729473890031747;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.1013495155434563, learning_rate=0.11191953783102526, max_depth=5, min_child_weight=1, n_estimators=90, subsample=1.0729473890031747;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.1013495155434563, learning_rate=0.11191953783102526, max_depth=5, min_child_weight=1, n_estimators=90, subsample=1.0729473890031747;, score=0.000 total time=   0.0s\n",
      "[17:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10135 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10135 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10135 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.9768342330413268, learning_rate=0.4449872304823313, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.736630464770127;, score=0.713 total time=   0.0s\n",
      "[17:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END colsample_bytree=0.9768342330413268, learning_rate=0.4449872304823313, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.736630464770127;, score=0.787 total time=   0.0s\n",
      "[17:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END colsample_bytree=0.9768342330413268, learning_rate=0.4449872304823313, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.736630464770127;, score=0.738 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END colsample_bytree=0.9768342330413268, learning_rate=0.4449872304823313, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.736630464770127;, score=0.823 total time=   0.0s\n",
      "[17:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END colsample_bytree=0.9768342330413268, learning_rate=0.4449872304823313, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.736630464770127;, score=0.722 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16908 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16908 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16908 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16908 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16908 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19647 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19647 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19647 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19647 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    Will return a dict of floats if `scorer` is a dict, otherwise a single\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 909, in fit\n",
      "    self._Booster = train(xgb_options, train_dmatrix,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 227, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 102, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1280, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19647 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  # e.g. unwrap memmapped scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.7103219354625228, learning_rate=0.4095561264170261, max_depth=9, min_child_weight=2, n_estimators=130, subsample=1.1690805830715651;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.7103219354625228, learning_rate=0.4095561264170261, max_depth=9, min_child_weight=2, n_estimators=130, subsample=1.1690805830715651;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.7103219354625228, learning_rate=0.4095561264170261, max_depth=9, min_child_weight=2, n_estimators=130, subsample=1.1690805830715651;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.7103219354625228, learning_rate=0.4095561264170261, max_depth=9, min_child_weight=2, n_estimators=130, subsample=1.1690805830715651;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.7103219354625228, learning_rate=0.4095561264170261, max_depth=9, min_child_weight=2, n_estimators=130, subsample=1.1690805830715651;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9992464354827109, learning_rate=0.5275221415080272, max_depth=6, min_child_weight=3, n_estimators=130, subsample=1.1964746649721385;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9992464354827109, learning_rate=0.5275221415080272, max_depth=6, min_child_weight=3, n_estimators=130, subsample=1.1964746649721385;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9992464354827109, learning_rate=0.5275221415080272, max_depth=6, min_child_weight=3, n_estimators=130, subsample=1.1964746649721385;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9992464354827109, learning_rate=0.5275221415080272, max_depth=6, min_child_weight=3, n_estimators=130, subsample=1.1964746649721385;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9992464354827109, learning_rate=0.5275221415080272, max_depth=6, min_child_weight=3, n_estimators=130, subsample=1.1964746649721385;, score=0.000 total time=   0.0s\n",
      "[17:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(error_score=0,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           gpu_id=-1, importance_type='gain',\n",
       "                                           interaction_constraints='',\n",
       "                                           learning_rate=0.300000012,\n",
       "                                           max_delta_step=0, max_depth=6,\n",
       "                                           min_child_weight=1, missing=nan,\n",
       "                                           monotone_constraints='()',\n",
       "                                           n_estimators=100, n_jobs...\n",
       "                   param_distributions={'colsample_bytree': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E6FD1FE0A0>,\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E6FD0AE490>,\n",
       "                                        'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [90, 100, 115, 130],\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E6FB797B50>},\n",
       "                   scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7804529544642649,\n",
       " 'learning_rate': 0.2934170571800207,\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 3,\n",
       " 'n_estimators': 90,\n",
       " 'subsample': 0.342166986259245}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgboost_clf = XGBClassifier(colsample_bytree=  0.7804529544642649,\n",
    " learning_rate= 0.2934170571800207,\n",
    " max_depth=9,\n",
    " min_child_weight= 3,\n",
    " n_estimators= 90,\n",
    " subsample= 0.342166986259245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:09:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7804529544642649, gamma=0,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.2934170571800207, max_delta_step=0, max_depth=9,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=90, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=0.342166986259245, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xgboost_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1=Xgboost_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1=accuracy_score(y_pred1,y_test)\n",
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 17],\n",
       "       [12, 37]], dtype=int64)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1=confusion_matrix(y_pred1,y_test)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score1 = Xgboost_clf.predict_proba(x_test)[:,1]\n",
    "y_score2 = model_rf.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)\n",
    "false_positive_rate2, true_positive_rate2, threshold2 = roc_curve(y_test, y_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic - XgBoost')\n",
    "plt.plot(false_positive_rate1, true_positive_rate1)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic - RandomForest')\n",
    "plt.plot(false_positive_rate2, true_positive_rate2)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score for XgBoost:  0.7407407407407408\n",
      "roc_auc_score for Random Forest:  0.7745571658615137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('roc_auc_score for XgBoost: ', roc_auc_score(y_test, y_score1))\n",
    "print('roc_auc_score for Random Forest: ', roc_auc_score(y_test, y_score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'E:\\College Project\\Deployment Folders\\Heart Disease Deployment'+ '/stroke.pkl', 'wb') as f:\n",
    "    pickle.dump(model_rf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
